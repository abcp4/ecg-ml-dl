{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "import tsai\n",
    "from tsai.all import *\n",
    "from tsai.imports import *\n",
    "from tsai.models.layers import *\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../../'))\n",
    "from utils import utils\n",
    "from utils.utils import evaluate_experiment\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from timeseries_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.basic_train import *\n",
    "from fastai.train import *\n",
    "from fastai.metrics import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.layers import *\n",
    "from fastai.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsai       : 0.1.0\n",
      "fastai2    : 0.0.17\n",
      "fastcore   : 0.1.17\n",
      "torch      : 1.4.0\n",
      "scipy      : 1.4.1\n",
      "numpy      : 1.18.1\n",
      "pandas     : 1.0.4\n",
      "Total RAM  : 62.75 GB\n",
      "Used RAM   :  3.91 GB\n",
      "n_cpus     : 16\n",
      "device     : cuda (GeForce GTX 1080)\n"
     ]
    }
   ],
   "source": [
    "print('tsai       :', tsai.__version__)\n",
    "print('fastai2    :', fastai2.__version__)\n",
    "print('fastcore   :', fastcore.__version__)\n",
    "print('torch      :', torch.__version__)\n",
    "print('scipy      :', sp.__version__)\n",
    "print('numpy      :', np.__version__)\n",
    "print('pandas     :', pd.__version__)\n",
    "print(f'Total RAM  : {bytes2GB(psutil.virtual_memory().total):5.2f} GB')\n",
    "print(f'Used RAM   : {bytes2GB(psutil.virtual_memory().used):5.2f} GB')\n",
    "print('n_cpus     :', cpus)\n",
    "iscuda = torch.cuda.is_available()\n",
    "if iscuda: print('device     : {} ({})'.format(device, torch.cuda.get_device_name(0)))\n",
    "else: print('device     :', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data='../../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(os.path.abspath(path_to_data+'data-002.npy'),allow_pickle=True)\n",
    "Y=np.load(path_to_data+'Y.npy',allow_pickle=True)\n",
    "labels =pd.read_csv(path_to_data+'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold=8\n",
    "val_fold=9\n",
    "test_fold=10\n",
    "\n",
    "# 10th fold for testing (9th for now)\n",
    "X_test = data[labels.strat_fold == test_fold]\n",
    "y_test = Y[labels.strat_fold == test_fold]\n",
    "# 9th fold for validation (8th for now)\n",
    "X_val = data[labels.strat_fold == val_fold]\n",
    "y_val = Y[labels.strat_fold == val_fold]\n",
    "# rest for training\n",
    "X_train = data[labels.strat_fold <= train_fold]\n",
    "y_train = Y[labels.strat_fold <= train_fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17111, 1000, 12), (2156, 1000, 12))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape ,X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess signal data\n",
    "X_train, X_val, X_test = utils.preprocess_signals(X_train, X_val, X_test,'/content/')\n",
    "n_classes = y_train.shape[1]\n",
    "# X_train = np.reshape(X_train,[X_train.shape[0],X_train.shape[2],X_train.shape[1]])\n",
    "# X_val = np.reshape(X_val,[X_val.shape[0],X_val.shape[2],X_val.shape[1]])\n",
    "X_test = np.reshape(X_test,[X_test.shape[0],X_test.shape[2],X_test.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17111, 1000, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.shape)\n",
    "_, features, seq_len = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17111, 1000, 12), (2156, 1000, 12))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17111, 5), (2156, 5))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Block(Module):\n",
    "    def __init__(self, ni, nf, ks=[7, 5, 3], act_fn='relu'):\n",
    "        self.conv1 = Conv1d(ni, nf, ks[0], padding='same', act_fn=act_fn)\n",
    "        self.conv2 = Conv1d(nf, nf, ks[1], padding='same', act_fn=act_fn)\n",
    "        self.conv3 = Conv1d(nf, nf, ks[2], padding='same', act_fn=False)\n",
    "\n",
    "        # expand channels for the sum if necessary\n",
    "        self.shortcut = noop if ni == nf else Conv1d(ni, nf, ks=1, act_fn=False)\n",
    "        self.act_fn = get_act_layer(act_fn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        sc = self.shortcut(res)\n",
    "        x += sc\n",
    "        x = self.act_fn(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResCNN(Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        nf = 64\n",
    "        self.block = Block(c_in, nf, ks=[7, 5, 3], act_fn='relu')\n",
    "        self.conv1 = Conv1d(nf, nf * 2, ks=3, padding='same', act_fn='leakyrelu', act_kwargs={'negative_slope':.2})\n",
    "        self.conv2 = Conv1d(nf * 2, nf * 4, ks=3, padding='same', act_fn='prelu')\n",
    "        self.conv3 = Conv1d(nf * 4, nf * 2, ks=3, padding='same', act_fn='elu', act_kwargs={'alpha':.3})\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.lin = nn.Linear(nf * 2, c_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.gap(x).squeeze(-1)\n",
    "        return self.lin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "    \n",
    "class SqueezeExcite1d(nn.Module):\n",
    "    '''squeeze excite block as used for example in LSTM FCN'''\n",
    "    def __init__(self,channels,reduction=16):\n",
    "        super().__init__()\n",
    "        channels_reduced = channels//reduction\n",
    "        self.w1 = torch.nn.Parameter(torch.randn(channels_reduced,channels).unsqueeze(0))\n",
    "        self.w2 = torch.nn.Parameter(torch.randn(channels, channels_reduced).unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #input is bs,ch,seq\n",
    "        z=torch.mean(x,dim=2,keepdim=True)#bs,ch\n",
    "        intermed = F.relu(torch.matmul(self.w1,z))#(1,ch_red,ch * bs,ch,1) = (bs, ch_red, 1)\n",
    "        s=F.sigmoid(torch.matmul(self.w2,intermed))#(1,ch,ch_red * bs, ch_red, 1=bs, ch, 1\n",
    "        return s*x #bs,ch,seq * bs, ch,1 = bs,ch,seq\n",
    "\n",
    "def weight_init(m):\n",
    "    '''call weight initialization for model n via n.appy(weight_init)'''\n",
    "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    if isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight,1)\n",
    "        nn.init.constant_(m.bias,0)\n",
    "    if isinstance(m,SqueezeExcite1d):\n",
    "        stdv1=math.sqrt(2./m.w1.size[0])\n",
    "        nn.init.normal_(m.w1,0.,stdv1)\n",
    "        stdv2=math.sqrt(1./m.w2.size[1])\n",
    "        nn.init.normal_(m.w2,0.,stdv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.binary_cross_entropy_with_logits\n",
    "input_size=X_train.shape[1]\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#batchsize\n",
    "bs=128\n",
    "model = ResNet(12,5).to(device)\n",
    "X_train_list = [l.astype(np.float32) for l in X_train]\n",
    "X_val_list = [l.astype(np.float32) for l in X_val]\n",
    "y_train_list = [l.astype(np.float32) for l in y_train]\n",
    "y_val_list = [l.astype(np.float32) for l in y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17111, 2156)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (block1): ResBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1dSame(\n",
       "        (conv1d_same): Conv1d(12, 64, kernel_size=(7,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1dSame(\n",
       "        (conv1d_same): Conv1d(64, 64, kernel_size=(5,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1dSame(\n",
       "        (conv1d_same): Conv1d(64, 64, kernel_size=(3,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1dSame(\n",
       "        (conv1d_same): Conv1d(12, 64, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act_fn): ReLU()\n",
       "  )\n",
       "  (block2): ResBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1dSame(\n",
       "        (conv1d_same): Conv1d(64, 128, kernel_size=(7,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1dSame(\n",
       "        (conv1d_same): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1dSame(\n",
       "        (conv1d_same): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (shortcut): Sequential(\n",
       "      (0): Conv1dSame(\n",
       "        (conv1d_same): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (act_fn): ReLU()\n",
       "  )\n",
       "  (block3): ResBlock(\n",
       "    (conv1): Sequential(\n",
       "      (0): Conv1dSame(\n",
       "        (conv1d_same): Conv1d(128, 128, kernel_size=(7,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv2): Sequential(\n",
       "      (0): Conv1dSame(\n",
       "        (conv1d_same): Conv1d(128, 128, kernel_size=(5,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (conv3): Sequential(\n",
       "      (0): Conv1dSame(\n",
       "        (conv1d_same): Conv1d(128, 128, kernel_size=(3,), stride=(1,))\n",
       "      )\n",
       "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (act_fn): ReLU()\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "  (squeeze): Squeeze()\n",
       "  (fc): Linear(in_features=128, out_features=5, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "wd=1e-2\n",
    "\n",
    "chunkify_train=False\n",
    "chunkify_valid=True\n",
    "chunk_length_valid=input_size\n",
    "min_chunk_length=input_size#chunk_length\n",
    "\n",
    "stride_length_train=input_size#chunk_length_train//8\n",
    "stride_length_valid=input_size//2#chunk_length_valid\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame({\"data\":range(len(X_train_list)),\"label\":y_train_list})\n",
    "df_valid = pd.DataFrame({\"data\":range(len(X_val_list)),\"label\":y_val_list})\n",
    "\n",
    "tfms_ptb_xl = [ToTensor()]\n",
    "\n",
    "ds_train=TimeseriesDatasetCrops(df_train,input_size,num_classes=5,chunk_length= 0,min_chunk_length=min_chunk_length,stride=stride_length_train,transforms=tfms_ptb_xl,annotation=False,col_lbl =\"label\",npy_data=X_train_list)\n",
    "ds_valid=TimeseriesDatasetCrops(df_valid,input_size,num_classes=5,chunk_length=chunk_length_valid,min_chunk_length=min_chunk_length,stride=stride_length_valid,transforms=tfms_ptb_xl,annotation=False,col_lbl =\"label\",npy_data=X_val_list)\n",
    "\n",
    "db = DataBunch.create(ds_train,ds_valid,bs=bs)\n",
    "learn = Learner(db,model, loss_func=loss, metrics=metrics,wd=wd,path='/content/models')\n",
    "learn.model.apply(weight_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.361467</td>\n",
       "      <td>0.417430</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.333577</td>\n",
       "      <td>0.381348</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.303319</td>\n",
       "      <td>0.324226</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.279579</td>\n",
       "      <td>0.298667</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.258910</td>\n",
       "      <td>0.283129</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(5,1e-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds,targs=learn.get_preds()\n",
    "preds = preds.numpy()\n",
    "targs = targs.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2156, 5), (2156, 5), (2156, 5))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape, y_val.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   macro_auc      Fmax\n",
      "0    0.92049  0.808577\n"
     ]
    }
   ],
   "source": [
    "thresholds=None\n",
    "tr_df_point = evaluate_experiment( targs, preds)\n",
    "print(tr_df_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
