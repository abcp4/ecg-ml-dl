{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "import tsai\n",
    "from tsai.all import *\n",
    "from tsai.imports import *\n",
    "from tsai.models.layers import *\n",
    "display(HTML(\"<style>.container {width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../../'))\n",
    "from utils import utils\n",
    "from utils.utils import evaluate_experiment\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "from timeseries_utils import *\n",
    "from scipy.fftpack import fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.basic_data import *\n",
    "from fastai.basic_train import *\n",
    "from fastai.train import *\n",
    "from fastai.metrics import *\n",
    "from fastai.torch_core import *\n",
    "from fastai.layers import *\n",
    "from fastai.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tsai       : 0.1.0\n",
      "fastai2    : 0.0.17\n",
      "fastcore   : 0.1.18\n",
      "torch      : 1.5.1\n",
      "scipy      : 1.5.0\n",
      "numpy      : 1.18.1\n",
      "pandas     : 1.0.5\n",
      "Total RAM  : 62.75 GB\n",
      "Used RAM   :  0.98 GB\n",
      "n_cpus     : 16\n",
      "device     : cuda (GeForce GTX 1080)\n"
     ]
    }
   ],
   "source": [
    "print('tsai       :', tsai.__version__)\n",
    "print('fastai2    :', fastai2.__version__)\n",
    "print('fastcore   :', fastcore.__version__)\n",
    "print('torch      :', torch.__version__)\n",
    "print('scipy      :', sp.__version__)\n",
    "print('numpy      :', np.__version__)\n",
    "print('pandas     :', pd.__version__)\n",
    "print(f'Total RAM  : {bytes2GB(psutil.virtual_memory().total):5.2f} GB')\n",
    "print(f'Used RAM   : {bytes2GB(psutil.virtual_memory().used):5.2f} GB')\n",
    "print('n_cpus     :', cpus)\n",
    "iscuda = torch.cuda.is_available()\n",
    "if iscuda: print('device     : {} ({})'.format(device, torch.cuda.get_device_name(0)))\n",
    "else: print('device     :', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data='../../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=np.load(os.path.abspath(path_to_data+'data-002.npy'),allow_pickle=True)\n",
    "Y=np.load(path_to_data+'Y.npy',allow_pickle=True)\n",
    "labels =pd.read_csv(path_to_data+'labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_fold=8\n",
    "val_fold=9\n",
    "test_fold=10\n",
    "\n",
    "# 10th fold for testing (9th for now)\n",
    "X_test = data[labels.strat_fold == test_fold]\n",
    "y_test = Y[labels.strat_fold == test_fold]\n",
    "# 9th fold for validation (8th for now)\n",
    "X_val = data[labels.strat_fold == val_fold]\n",
    "y_val = Y[labels.strat_fold == val_fold]\n",
    "# rest for training\n",
    "X_train = data[labels.strat_fold <= train_fold]\n",
    "y_train = Y[labels.strat_fold <= train_fold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17111, 1000, 12), (2156, 1000, 12))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape ,X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess signal data\n",
    "X_train, X_val, X_test = utils.preprocess_signals(X_train, X_val, X_test,'/content/')\n",
    "n_classes = y_train.shape[1]\n",
    "# X_train = np.reshape(X_train,[X_train.shape[0],X_train.shape[2],X_train.shape[1]])\n",
    "# X_val = np.reshape(X_val,[X_val.shape[0],X_val.shape[2],X_val.shape[1]])\n",
    "X_test = np.reshape(X_test,[X_test.shape[0],X_test.shape[2],X_test.shape[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17111, 1000, 12)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_train.shape)\n",
    "_, features, seq_len = X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17111, 1000, 12), (2156, 1000, 12))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17111, 5), (2156, 5))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get fourier transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17111, 1000, 12), (17111, 1000, 12), (2156, 1000, 12), (17111, 5))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N=1000\n",
    "X_train_fft = fft(X_train)\n",
    "X_train_fft = (2/N) * np.abs(X_train_fft)\n",
    "\n",
    "X_val_fft = fft(X_val)\n",
    "X_val_fft = (2/N) * np.abs(X_val_fft)\n",
    "\n",
    "X_train.shape, X_train_fft.shape, X_val_fft.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17111, 1000, 12), (17111, 1000, 12), (2156, 1000, 12), (17111, 5))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_train_fft.shape, X_val_fft.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate FFT to Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.dstack((X_train,X_train_fft))\n",
    "X_val = np.dstack((X_val,X_val_fft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((17111, 1000, 24), (2156, 1000, 24))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "# This is an unofficial PyTorch implementation by Ignacio Oguiza - oguiza@gmail.com based on:\n",
    "\n",
    "# Fawaz, H. I., Lucas, B., Forestier, G., Pelletier, C., Schmidt, D. F., Weber, J., ... & Petitjean, F. (2019). \n",
    "# InceptionTime: Finding AlexNet for Time Series Classification. arXiv preprint arXiv:1909.04939.\n",
    "# Official InceptionTime tensorflow implementation: https://github.com/hfawaz/InceptionTime\n",
    "\n",
    "class _SepConv1d(nn.Module):\n",
    "    \"\"\"A simple separable convolution implementation.\n",
    "    \n",
    "    The separable convlution is a method to reduce number of the parameters \n",
    "    in the deep learning network for slight decrease in predictions quality.\n",
    "    \"\"\"\n",
    "    def __init__(self, ni, no, kernel, stride, pad):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv1d(ni, ni, kernel, stride, padding=pad, groups=ni)\n",
    "        self.pointwise = nn.Conv1d(ni, no, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "\n",
    "class SepConv1d(nn.Module):\n",
    "    \"\"\"Implementes a 1-d convolution with 'batteries included'.\n",
    "    \n",
    "    The module adds (optionally) activation function and dropout layers right after\n",
    "    a separable convolution layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, ni, no, kernel, stride, pad, drop=None,\n",
    "                 activ=lambda: nn.ReLU(inplace=True)):\n",
    "    \n",
    "        super().__init__()\n",
    "        assert drop is None or (0.0 < drop < 1.0)\n",
    "        layers = [_SepConv1d(ni, no, kernel, stride, pad)]\n",
    "        if activ:\n",
    "            layers.append(activ())\n",
    "        if drop is not None:\n",
    "            layers.append(nn.Dropout(drop))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.layers(x)\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    \"\"\"Converts N-dimensional tensor into 'flat' one.\"\"\"\n",
    "\n",
    "    def __init__(self, keep_batch_dim=True):\n",
    "        super().__init__()\n",
    "        self.keep_batch_dim = keep_batch_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.keep_batch_dim:\n",
    "            return x.view(x.size(0), -1)\n",
    "        return x.view(-1)\n",
    "    \n",
    "def shortcut(c_in, c_out):\n",
    "    return nn.Sequential(*[nn.Conv1d(c_in, c_out, kernel_size=1), nn.BatchNorm1d(c_out)])\n",
    "    \n",
    "    \n",
    "class Inception(Module):\n",
    "    def __init__(self, c_in, bottleneck=32, ks=40, nb_filters=32):\n",
    "        self.bottleneck = nn.Conv1d(c_in, bottleneck, 1) if bottleneck and c_in > 1 else noop\n",
    "        mts_feat = bottleneck or c_in\n",
    "        conv_layers = []\n",
    "        kss = [ks // (2**i) for i in range(3)]\n",
    "        # ensure odd kss until nn.Conv1d with padding='same' is available in pytorch\n",
    "        kss = [ksi if ksi % 2 != 0 else ksi - 1 for ksi in kss] \n",
    "        for i in range(len(kss)): conv_layers.append(nn.Conv1d(mts_feat, nb_filters, kernel_size=kss[i], padding=kss[i]//2))\n",
    "        self.conv_layers = nn.ModuleList(conv_layers)\n",
    "        self.maxpool = nn.MaxPool1d(3, stride=1, padding=1)\n",
    "        self.conv = nn.Conv1d(c_in, nb_filters, kernel_size=1)\n",
    "        self.bn = nn.BatchNorm1d(nb_filters * 4)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = x\n",
    "        x = self.bottleneck(input_tensor)\n",
    "        for i in range(3):\n",
    "            out_ = self.conv_layers[i](x)\n",
    "            if i == 0: out = out_\n",
    "            else: out = torch.cat((out, out_), 1)\n",
    "        mp = self.conv(self.maxpool(input_tensor))\n",
    "        inc_out = torch.cat((out, mp), 1)\n",
    "        return self.act(self.bn(inc_out))\n",
    "\n",
    "\n",
    "class InceptionBlock(Module):\n",
    "    def __init__(self,c_in,bottleneck=32,ks=40,nb_filters=32,residual=True,depth=6):\n",
    "        self.residual = residual\n",
    "        self.depth = depth\n",
    "\n",
    "        #inception & residual layers\n",
    "        inc_mods = []\n",
    "        res_layers = []\n",
    "        res = 0\n",
    "        for d in range(depth):\n",
    "            inc_mods.append(Inception(c_in if d == 0 else nb_filters * 4, bottleneck=bottleneck if d > 0 else 0,ks=ks, nb_filters=nb_filters))\n",
    "            if self.residual and d % 3 == 2:\n",
    "                res_layers.append(shortcut(c_in if res == 0 else nb_filters * 4, nb_filters * 4))\n",
    "                res += 1\n",
    "            else: res_layer = res_layers.append(None)\n",
    "        self.inc_mods = nn.ModuleList(inc_mods)\n",
    "        self.res_layers = nn.ModuleList(res_layers)\n",
    "        self.act = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        for d, l in enumerate(range(self.depth)):\n",
    "            x = self.inc_mods[d](x)\n",
    "            if self.residual and d % 3 == 2:\n",
    "                res = self.res_layers[d](res)\n",
    "                x += res\n",
    "                res = x\n",
    "                x = self.act(x)\n",
    "        return x\n",
    "    \n",
    "class InceptionTime(Module):\n",
    "    def __init__(self,c_in,c_in_fft,c_out,bottleneck=32,ks=40,nb_filters=32,residual=True,depth=6, drop=.5):\n",
    "        self.c_in = c_in\n",
    "        self.block = InceptionBlock(c_in, bottleneck=bottleneck, ks=ks, nb_filters=nb_filters, residual=residual, depth=depth)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        self.squeeze = Squeeze(-1)\n",
    "        size_in_fc = (nb_filters * 4) * 2\n",
    "        self.fc = nn.Linear(size_in_fc, c_out)\n",
    "        \n",
    "        \n",
    "        self.fft = nn.Sequential(\n",
    "            SepConv1d(c_in_fft,  32, 5, 2, 3, drop=drop),\n",
    "            SepConv1d(    32,  64, 5, 4, 2, drop=drop),\n",
    "            SepConv1d(    64, 128, 5, 4, 2, drop=drop),\n",
    "            SepConv1d(   128, 128, 5, 4, 2, drop=drop),\n",
    "            SepConv1d(   128, 256, 5, 4, 2),\n",
    "            Flatten(),\n",
    "            nn.Dropout(drop), nn.Linear(512, 256), nn.ReLU(inplace=True), # here was 256,64\n",
    "            nn.Dropout(drop), nn.Linear(256, 128), nn.ReLU(inplace=True))\n",
    "                            \n",
    "    def raw(self, x):\n",
    "        x = self.block(x)\n",
    "        x = self.squeeze(self.gap(x))\n",
    "        #x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "#     def fft(self, x):\n",
    "#         x = self.block(x)\n",
    "#         x = self.squeeze(self.gap(x))\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, x_fft = torch.split(x, self.c_in, dim=1) # it returns a tuple\n",
    "        x, x_fft = x.to(device), x_fft.to(device)\n",
    "        out_raw = self.raw(x)\n",
    "        out_fft = self.fft(x_fft)\n",
    "        x = torch.cat([out_raw, out_fft], dim=1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "    \n",
    "class SqueezeExcite1d(nn.Module):\n",
    "    '''squeeze excite block as used for example in LSTM FCN'''\n",
    "    def __init__(self,channels,reduction=16):\n",
    "        super().__init__()\n",
    "        channels_reduced = channels//reduction\n",
    "        self.w1 = torch.nn.Parameter(torch.randn(channels_reduced,channels).unsqueeze(0))\n",
    "        self.w2 = torch.nn.Parameter(torch.randn(channels, channels_reduced).unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #input is bs,ch,seq\n",
    "        z=torch.mean(x,dim=2,keepdim=True)#bs,ch\n",
    "        intermed = F.relu(torch.matmul(self.w1,z))#(1,ch_red,ch * bs,ch,1) = (bs, ch_red, 1)\n",
    "        s=F.sigmoid(torch.matmul(self.w2,intermed))#(1,ch,ch_red * bs, ch_red, 1=bs, ch, 1\n",
    "        return s*x #bs,ch,seq * bs, ch,1 = bs,ch,seq\n",
    "\n",
    "def weight_init(m):\n",
    "    '''call weight initialization for model n via n.appy(weight_init)'''\n",
    "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.zeros_(m.bias)\n",
    "    if isinstance(m, nn.BatchNorm1d):\n",
    "        nn.init.constant_(m.weight,1)\n",
    "        nn.init.constant_(m.bias,0)\n",
    "    if isinstance(m,SqueezeExcite1d):\n",
    "        stdv1=math.sqrt(2./m.w1.size[0])\n",
    "        nn.init.normal_(m.w1,0.,stdv1)\n",
    "        stdv2=math.sqrt(1./m.w2.size[1])\n",
    "        nn.init.normal_(m.w2,0.,stdv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = F.binary_cross_entropy_with_logits\n",
    "input_size=X_train.shape[1]\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#batchsize\n",
    "bs=128\n",
    "model = InceptionTime(c_in=12,c_in_fft=12,c_out=5).to(device)\n",
    "X_train_list = [l.astype(np.float32) for l in X_train]\n",
    "X_val_list = [l.astype(np.float32) for l in X_val]\n",
    "y_train_list = [l.astype(np.float32) for l in y_train]\n",
    "y_val_list = [l.astype(np.float32) for l in y_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17111, 2156)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InceptionTime(\n",
       "  (block): InceptionBlock(\n",
       "    (inc_mods): ModuleList(\n",
       "      (0): Inception(\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Conv1d(12, 32, kernel_size=(39,), stride=(1,), padding=(19,))\n",
       "          (1): Conv1d(12, 32, kernel_size=(19,), stride=(1,), padding=(9,))\n",
       "          (2): Conv1d(12, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        )\n",
       "        (maxpool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (conv): Conv1d(12, 32, kernel_size=(1,), stride=(1,))\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "      )\n",
       "      (1): Inception(\n",
       "        (bottleneck): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,))\n",
       "          (2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        )\n",
       "        (maxpool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "      )\n",
       "      (2): Inception(\n",
       "        (bottleneck): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,))\n",
       "          (2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        )\n",
       "        (maxpool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "      )\n",
       "      (3): Inception(\n",
       "        (bottleneck): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,))\n",
       "          (2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        )\n",
       "        (maxpool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "      )\n",
       "      (4): Inception(\n",
       "        (bottleneck): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,))\n",
       "          (2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        )\n",
       "        (maxpool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "      )\n",
       "      (5): Inception(\n",
       "        (bottleneck): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "        (conv_layers): ModuleList(\n",
       "          (0): Conv1d(32, 32, kernel_size=(39,), stride=(1,), padding=(19,))\n",
       "          (1): Conv1d(32, 32, kernel_size=(19,), stride=(1,), padding=(9,))\n",
       "          (2): Conv1d(32, 32, kernel_size=(9,), stride=(1,), padding=(4,))\n",
       "        )\n",
       "        (maxpool): MaxPool1d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "        (conv): Conv1d(128, 32, kernel_size=(1,), stride=(1,))\n",
       "        (bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (res_layers): ModuleList(\n",
       "      (0): None\n",
       "      (1): None\n",
       "      (2): Sequential(\n",
       "        (0): Conv1d(12, 128, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): None\n",
       "      (4): None\n",
       "      (5): Sequential(\n",
       "        (0): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (act): ReLU()\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool1d(output_size=1)\n",
       "  (squeeze): Squeeze()\n",
       "  (fc): Linear(in_features=256, out_features=5, bias=True)\n",
       "  (fft): Sequential(\n",
       "    (0): SepConv1d(\n",
       "      (layers): Sequential(\n",
       "        (0): _SepConv1d(\n",
       "          (depthwise): Conv1d(12, 12, kernel_size=(5,), stride=(2,), padding=(3,), groups=12)\n",
       "          (pointwise): Conv1d(12, 32, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (1): SepConv1d(\n",
       "      (layers): Sequential(\n",
       "        (0): _SepConv1d(\n",
       "          (depthwise): Conv1d(32, 32, kernel_size=(5,), stride=(4,), padding=(2,), groups=32)\n",
       "          (pointwise): Conv1d(32, 64, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (2): SepConv1d(\n",
       "      (layers): Sequential(\n",
       "        (0): _SepConv1d(\n",
       "          (depthwise): Conv1d(64, 64, kernel_size=(5,), stride=(4,), padding=(2,), groups=64)\n",
       "          (pointwise): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (3): SepConv1d(\n",
       "      (layers): Sequential(\n",
       "        (0): _SepConv1d(\n",
       "          (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(4,), padding=(2,), groups=128)\n",
       "          (pointwise): Conv1d(128, 128, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): ReLU(inplace=True)\n",
       "        (2): Dropout(p=0.5, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (4): SepConv1d(\n",
       "      (layers): Sequential(\n",
       "        (0): _SepConv1d(\n",
       "          (depthwise): Conv1d(128, 128, kernel_size=(5,), stride=(4,), padding=(2,), groups=128)\n",
       "          (pointwise): Conv1d(128, 256, kernel_size=(1,), stride=(1,))\n",
       "        )\n",
       "        (1): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Flatten()\n",
       "    (6): Dropout(p=0.5, inplace=False)\n",
       "    (7): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): Dropout(p=0.5, inplace=False)\n",
       "    (10): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (11): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = [accuracy]\n",
    "wd=1e-2\n",
    "\n",
    "chunkify_train=False\n",
    "chunkify_valid=True\n",
    "chunk_length_valid=input_size\n",
    "min_chunk_length=input_size#chunk_length\n",
    "\n",
    "stride_length_train=input_size#chunk_length_train//8\n",
    "stride_length_valid=input_size//2#chunk_length_valid\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame({\"data\":range(len(X_train_list)),\"label\":y_train_list})\n",
    "df_valid = pd.DataFrame({\"data\":range(len(X_val_list)),\"label\":y_val_list})\n",
    "\n",
    "tfms_ptb_xl = [ToTensor()]\n",
    "\n",
    "ds_train=TimeseriesDatasetCrops(df_train,input_size,num_classes=5,chunk_length= 0,min_chunk_length=min_chunk_length,stride=stride_length_train,transforms=tfms_ptb_xl,annotation=False,col_lbl =\"label\",npy_data=X_train_list)\n",
    "ds_valid=TimeseriesDatasetCrops(df_valid,input_size,num_classes=5,chunk_length=chunk_length_valid,min_chunk_length=min_chunk_length,stride=stride_length_valid,transforms=tfms_ptb_xl,annotation=False,col_lbl =\"label\",npy_data=X_val_list)\n",
    "\n",
    "db = DataBunch.create(ds_train,ds_valid,bs=bs)\n",
    "learn = Learner(db,model, loss_func=loss, metrics=metrics,wd=wd,path='/content/models')\n",
    "learn.model.apply(weight_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='10' class='' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      33.33% [10/30 04:30<09:00]\n",
       "    </div>\n",
       "    \n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.325439</td>\n",
       "      <td>0.343670</td>\n",
       "      <td>0.163915</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.307376</td>\n",
       "      <td>0.419427</td>\n",
       "      <td>0.322263</td>\n",
       "      <td>00:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.299459</td>\n",
       "      <td>0.356552</td>\n",
       "      <td>0.186085</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.610613</td>\n",
       "      <td>0.326929</td>\n",
       "      <td>0.135900</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7.966377</td>\n",
       "      <td>0.314893</td>\n",
       "      <td>0.127737</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>313.719513</td>\n",
       "      <td>0.348276</td>\n",
       "      <td>0.121521</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2114.740479</td>\n",
       "      <td>0.322598</td>\n",
       "      <td>0.083210</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>151.550369</td>\n",
       "      <td>0.326520</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>229.460342</td>\n",
       "      <td>0.554322</td>\n",
       "      <td>0.051484</td>\n",
       "      <td>00:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>142.903702</td>\n",
       "      <td>0.302076</td>\n",
       "      <td>0.104638</td>\n",
       "      <td>00:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='37' class='' max='133' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      27.82% [37/133 00:07<00:20 151.5642]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(30,1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randn(128, 24, 1000) #tensor of size 50 x 80\n",
    "b = torch.split(a, 12, dim=1) # it returns a tuple\n",
    "b[0].size(),b[1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_losses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.recorder.plot_lr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds,targs=learn.get_preds()\n",
    "preds = preds.numpy()\n",
    "targs = targs.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import evaluate_experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "thresholds=None\n",
    "tr_df_point = evaluate_experiment(targs, preds)\n",
    "print(tr_df_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_df_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
